# Image-Text Matching Summary
Summary of Related Research on Image-Text Matching

- [Papers](#Papers): [Conference](#Conference), [Journal](#Journal)
- [Datasets](#Datasets): [Flickr30K](#Flickr30K), [MS-COCO](#MS-COCO)
- [Performance](#Performance)

## Papers

### Conference

#### 2023

- `[2023 CVPR]` **Learning Semantic Relationship among Instances for Image-Text Matching (HREM)**  
*Zheren Fu, Zhendong Mao, Yan Song, Yongdong Zhang*  
[[paper]](https://openaccess.thecvf.com/content/CVPR2023/papers/Pan_Fine-Grained_Image-Text_Matching_by_Cross-Modal_Hard_Aligning_Network_CVPR_2023_paper.pdf)
[[code]](https://github.com/CrossmodalGroup/HREM)

- `[2023 CVPR]` **Fine-Grained Image-Text Matching by Cross-Modal Hard Aligning Network (CHAN)**  
*Zhengxin Pan, Fangyu Wu, Bailing Zhang*  
[[paper]](https://openaccess.thecvf.com/content/CVPR2023/papers/Pan_Fine-Grained_Image-Text_Matching_by_Cross-Modal_Hard_Aligning_Network_CVPR_2023_paper.pdf)
[[code]](https://github.com/ppanzx/CHAN)

- `[2023 CVPR]` **BiCro: Noisy Correspondence Rectification for Multi-modality Data via Bi-directional Cross-modal Similarity Consistency (BiCro)**  
*Shuo Yang, Zhaopan Xu, Kai Wang, Yang You, Hongxun Yao, Tongliang Liu, Min Xu*  
[[paper]](https://arxiv.org/pdf/2303.12419)
[[code]](https://github.com/xu5zhao/BiCro)

- `[2023 CVPR]` **Improving Cross-Modal Retrieval with Set of Diverse Embeddings**  
*Dongwon Kim, Namyup Kim, Suha Kwak*  
[[paper]](https://arxiv.org/pdf/2211.16761)

- `[2023 SIGIR]` **Learnable Pillar-based Re-ranking for Image-Text Retrieval**  
*Leigang Qu, Meng Liu, Wenjie Wang, Zhedong Zheng, Liqiang Nie, Tat-Seng Chua*  
[[paper]](https://arxiv.org/pdf/2304.12570)

- `[2023 SIGIR]` **Rethinking Benchmarks for Cross-modal Image-text Retrieval**  
*Weijing Chen, Linli Yao, Qin Jin*  
[[paper]](https://arxiv.org/pdf/2304.10824)

- `[2023 WACV]` **Dissecting Deep Metric Learning Losses for Image-Text Retrieval**  
*Hong Xuan, Xi (Stephen) Chen*  
[[paper]](https://openaccess.thecvf.com/content/WACV2023/papers/Xuan_Dissecting_Deep_Metric_Learning_Losses_for_Image-Text_Retrieval_WACV_2023_paper.pdf)

- `[2023 WACV]` **Cross-modal Semantic Enhanced Interaction for Image-Sentence Retrieval (CMSEI)**  
*Xuri Ge, Fuhai Chen, Songpei Xu, Fuxiang Tao, Joemon M. Jose*  
[[paper]](https://arxiv.org/pdf/2210.08908)

- `[2023 WACV]` **More Than Just Attention: Improving Cross-Modal Attentions with Contrastive Constraints for Image-Text Matching**  
*Yuxiao Chen, Jianbo Yuan, Long Zhao, Tianlang Chen, Rui Luo, Larry Davis, Dimitris N. Metaxas*  
[[paper]](https://arxiv.org/pdf/2105.09597)

#### 2022

- `[2022 ECCV]` **CODER: Coupled Diversity-Sensitive Momentum Contrastive Learning for Image-Text Retrieval (CODER)**  
*Haoran Wang, Dongliang He, Wenhao Wu, Boyang Xia, Min Yang, Fu Li, Yunlong Yu, Zhong Ji, Errui Ding, Jingdong Wang*  
[[paper]](https://arxiv.org/pdf/2208.09843.pdf)

- `[2022 CVPR]` **Negative-Aware Attention Framework for Image-Text Matching (NAAF)**  
*Kun Zhang, Zhendong Mao, Quan Wang, Yongdong Zhang*  
[[paper]](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Negative-Aware_Attention_Framework_for_Image-Text_Matching_CVPR_2022_paper.pdf)
[[code]](https://github.com/CrossmodalGroup/NAAF)

- `[2022 AAAI]` **Show Your Faith: Cross-Modal Confidence-Aware Network for Image-Text Matching (CMCAN)**  
*Huatian Zhang, Zhendong Mao, Kun Zhang, Yongdong Zhang*  
[[paper]](https://www.aaai.org/AAAI22Papers/AAAI-2029.ZhangH.pdf)
[[code]](https://github.com/CrossmodalGroup/CMCAN)

- `[2022 IJCAI]` **Multi-View Visual Semantic Embedding (MV-VSE)**  
*Zheng Li, Caili Guo, Zerun Feng, Jenq-Neng Hwang, Xijun Xue*  
[[paper]](https://www.ijcai.org/proceedings/2022/0158.pdf)

- `[2022 IJCAI]` **Image-text Retrieval: A Survey on Recent Research and Development**  
*Min Cao, Shiping Li, Juntao Li, Liqiang Nie, Min Zhang*  
[[paper]](https://arxiv.org/pdf/2203.14713)

- `[2022 SIGIR]` **Where Does the Performance Improvement Come From? -- A Reproducibility Concern about Image-Text Retrieval**  
*Jun Rao, Fei Wang, Liang Ding, Shuhan Qi, Yibing Zhan, Weifeng Liu, Dacheng Tao*  
[[paper]](https://arxiv.org/pdf/2203.03853)
[[code]](https://github.com/WangFei-2019/Image-text-Retrieval)

#### 2021

- `[2021 ICCV]` **Wasserstein Coupled Graph Learning for Cross-Modal Retrieval (WCGL)**  
*Yun Wang, Tong Zhang, Xueya Zhang, Zhen Cui, Yuge Huang, Pengcheng Shen, Shaoxin Li, Jian Yang*  
[[paper]](https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Wasserstein_Coupled_Graph_Learning_for_Cross-Modal_Retrieval_ICCV_2021_paper.pdf)

- `[2021 CVPR]` **Discrete-continuous Action Space Policy Gradient-based Attention for Image-Text Matching**  
*Shiyang Yan, Li Yu, Yuan Xie*  
[[paper]](https://arxiv.org/abs/2104.10406)
[[code]](https://github.com/Shiyang-Yan/Discrete-continous-PG-for-Retrieval)

- `[2021 CVPR]` **Learning the Best Pooling Strategy for Visual Semantic Embedding (GPO)**  
*Jiacheng Chen, Hexiang Hu, Hao Wu, Yuning Jiang, Changhu Wang*  
[[paper]](https://arxiv.org/pdf/2011.04305)
[[code]](https://github.com/woodfrog/vse_infty)

- `[2021 AAAI]` **Similarity Reasoning and Filtration for Image-Text Matching (SGRAF)**  
*Haiwen Diao, Ying Zhang, Lin Ma, Huchuan Lu*  
[[paper]](https://arxiv.org/pdf/2101.01368)
[[code]](https://github.com/Paranioar/SGRAF)

#### 2020

- `[2020 CVPR]` **Graph Structured Network for Image-Text Matching (GSMN)**  
*Chunxiao Liu, Zhendong Mao, Tianzhu Zhang, Hongtao Xie, Bin Wang, Yongdong Zhang*  
[[paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Liu_Graph_Structured_Network_for_Image-Text_Matching_CVPR_2020_paper.pdf)
[[code]](https://github.com/CrossmodalGroup/GSMN)

- `[2020 CVPR]` **IMRAM: Iterative Matching with Recurrent Attention Memory for Cross-Modal Image-Text Retrieval (IMRAM)**  
*Hui Chen, Guiguang Ding, Xudong Liu, Zijia Lin, Ji Liu, Jungong Han*  
[[paper]](https://arxiv.org/abs/2003.03772)
[[code]](https://github.com/HuiChen24/IMRAM)

- `[2020 CVPR]` **Context-Aware Attention Network for Image-Text Retrieval (CAAN)**  
*Qi Zhang, Zhen Lei, Zhaoxiang Zhang, Stan Z. Li*  
[[paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Context-Aware_Attention_Network_for_Image-Text_Retrieval_CVPR_2020_paper.pdf)

- `[2020 CVPR]` **Multi-Modality Cross Attention Network for Image and Sentence Matching (MMCA)**  
*Xi Wei, Tianzhu Zhang, Yan Li, Yongdong Zhang, Feng Wu*  
[[paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Wei_Multi-Modality_Cross_Attention_Network_for_Image_and_Sentence_Matching_CVPR_2020_paper.pdf)

- `[2020 CVPR]` **Universal Weighting Metric Learning for Cross-Modal Matching**  
*Jiwei Wei, Xing Xu, Yang Yang, Yanli Ji, Zheng Wang, Heng Tao Shen*  
[[paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Wei_Universal_Weighting_Metric_Learning_for_Cross-Modal_Matching_CVPR_2020_paper.pdf)
[[code]](https://github.com/wayne980/PolyLoss)

- `[2020 ECCV]` **Consensus-Aware Visual-Semantic Embedding for Image-Text Matching (CVSE)**  
*Haoran Wang, Ying Zhang, Zhong Ji, Yanwei Pang, Lin Ma*  
[[paper]](https://arxiv.org/pdf/2007.08883)
[[code]](https://github.com/BruceW91/CVSE)

- `[2020 ECCV]` **Adaptive Offline Quintuplet Loss for Image-Text Matching (AOQ)**  
*Tianlang Chen, Jiajun Deng, Jiebo Luo*  
[[paper]](https://arxiv.org/abs/2003.03669)
[[code]](https://github.com/sunnychencool/AOQ)

#### 2019

- `[2019 ICCV]` **Visual Semantic Reasoning for Image-Text Matching (VSRN)**  
*Kunpeng Li, Yulun Zhang, Kai Li, Yuanyuan Li, Yun Fu*  
[[paper]](https://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Visual_Semantic_Reasoning_for_Image-Text_Matching_ICCV_2019_paper.pdf)
[[code]](https://github.com/KunpengLi1994/VSRN)

- `[2019 ICCV]` **CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval (CAMP)**  
*Zihao Wang, Xihui Liu, Hongsheng Li, Lu Sheng, Junjie Yan, Xiaogang Wang, Jing Shao*  
[[paper]](https://arxiv.org/abs/1909.05506)
[[code]](https://github.com/ZihaoWang-CV/CAMP_iccv19)

- `[2019 ICCV]` **Saliency-Guided Attention Network for Image-Sentence Matching (SAN)**  
*Zhong Ji, Haoran Wang, Jungong Han, Yanwei Pang*  
[[paper]](https://arxiv.org/abs/1904.09471)
[[code]](https://github.com/HabbakukWang1103/SAN)

- `[2019 ICCV]` **Language-Agnostic Visual-Semantic Embeddings (LIWE)**  
*Jonatas Wehrmann, Maur√≠cio Armani Lopes, Douglas Souza, Rodrigo Barros*  
[[paper]](https://openaccess.thecvf.com/content_ICCV_2019/papers/Wehrmann_Language-Agnostic_Visual-Semantic_Embeddings_ICCV_2019_paper.pdf)
[[code]](https://github.com/jwehrmann/lavse)

- `[2019 CVPR]` **Polysemous Visual-Semantic Embedding for Cross-Modal Retrieval (PVSE)**  
*Yale Song, Mohammad Soleymani*  
[[paper]](https://arxiv.org/abs/1906.04402)
[[code]](https://github.com/yalesong/pvse)

- `[2019 ACM MM]` **Focus Your Attention: A Bidirectional Focal Attention Network for Image-Text Matching (BFAN)**  
*Chunxiao Liu, Zhendong Mao, An-An Liu, Tianzhu Zhang, Bin Wang, Yongdong Zhang*  
[[paper]](https://arxiv.org/abs/1909.11416)
[[code]](https://github.com/CrossmodalGroup/BFAN)

- `[2019 IJCAI]` **Position Focused Attention Network for Image-Text Matching (PFAN)**  
*Yaxiong Wang, Hao Yang, Xueming Qian, Lin Ma, Jing Lu, Biao Li, Xin Fan*  
[[paper]](https://arxiv.org/pdf/1907.09748)
[[code]](https://github.com/HaoYang0123/Position-Focused-Attention-Network)

#### 2018

- `[2018 ECCV]` **Stacked Cross Attention for Image-Text Matching (SCAN)**  
*Kuang-Huei Lee, Xi Chen, Gang Hua, Houdong Hu, Xiaodong He*  
[[paper]](http://openaccess.thecvf.com/content_ECCV_2018/papers/Kuang-Huei_Lee_Stacked_Cross_Attention_ECCV_2018_paper.pdf)
[[code]](https://github.com/kuanghuei/SCAN)

- `[2018 BMVC]` **VSE++: Improving Visual-Semantic Embeddings with Hard Negatives (VSE++)**  
*Fartash Faghri, David J. Fleet, Jamie Ryan Kiros, Sanja Fidler*  
[[paper]](https://arxiv.org/pdf/1707.05612)
[[code]](https://github.com/fartashf/vsepp)

### Journal

#### 2023

- `[2023 TPAMI]` **Cross-Modal Retrieval with Partially Mismatched Pairs (RCL)**  
*Peng Hu, Zhenyu Huang, Dezhong Peng, Xu Wang, Xi Peng*  
[[paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10050111)
[[code]](https://github.com/penghu-cs/RCL)

- `[2023 TIP]` **Plug-and-Play Regulators for Image-Text Matching (RCAR)**  
*Haiwen Diao, Ying Zhang, Wei Liu, Xiang Ruan, Huchuan Lu*  
[[paper]](https://arxiv.org/pdf/2303.13371)
[[code]](https://github.com/Paranioar/RCAR)

- `[2023 TMM]` **Integrating Language Guidance into Image-Text Matching for Correcting False Negatives (LG)**  
*Zheng Li, Caili Guo, Zerun Feng, Jenq-Neng Hwang, Zhongtian Du*  
[[paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10081045)
[[code]](https://github.com/AAA-Zheng/LG_ITM)

- `[2023 TMM]` **Inter-Intra Modal Representation Augmentation with DCT-Transformer Adversarial Network for Image-Text Matching (DTAN)**  
*Chen Chen, Dan Wang, Bin Song, Hao Tan*  
[[paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10041445)

#### 2022

- `[2022 TIP]` **Adaptive Latent Graph Representation Learning for Image-Text Matching**  
*Mengxiao Tian, Xinxiao Wu, Yunde Jia*  
[[paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9991857)

- `[2022 TMM]` **Unified Adaptive Relevance Distinguishable Attention Network for Image-Text Matching (UARDA)**  
*Kun Zhang, Zhendong Mao, Anan Liu, Yongdong Zhang*  
[[paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9676463)

- `[2022 TCSVT]` **Hierarchical Feature Aggregation Based on Transformer for Image-Text Matching (HAT)**  
*Xinfeng Dong, Huaxiang Zhang, Lei Zhu, Liqiang Nie, Li Liu*  
[[paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9745936)

#### 2020

- `[2020 TOMM]` **Dual-path Convolutional Image-Text Embeddings with Instance Loss**  
*Zhedong Zheng, Liang Zheng, Michael Garrett, Yi Yang, Mingliang Xu, YiDong Shen*  
[[paper]](https://arxiv.org/pdf/1711.05535)
[[code]](https://github.com/layumi/Image-Text-Embedding)

- `[2020 TNNLS]` **Cross-Modal Attention With Semantic Consistence for Image‚ÄìText Matching (CASC)**  
*Xing Xu, Tan Wang, Yang Yang, Lin Zuo, Fumin Shen, Heng Tao Shen*  
[[paper]](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8994196)


## Datasets
### Flickr30K
`[2014 TACL]` **From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions**  
*Peter Young, Alice Lai, Micah Hodosh, Julia Hockenmaier*  
[[paper]](https://aclanthology.org/Q14-1006.pdf)

### MS-COCO  
`[2014 ECCV]` **Microsoft COCO: Common Objects in Context**  
*Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll√°r & C. Lawrence Zitnick*  
[[paper]](https://projet.liris.cnrs.fr/imagine/pub/proceedings/ECCV-2014/papers/8693/86930740.pdf)

## Performance

### Performance on Flickr30K
<table>
  <tr>
    <td rowspan=2 align='center'>Model</td>
    <td rowspan=2 align='center'>Reference</td>
    <td rowspan=2 align='center'>Image Encoder</td>
    <td rowspan=2 align='center'>Text Encoder</td>
    <td colspan=3 align='center'>Image-to-Text</td>
    <td colspan=3 align='center'>Text-to-Image</td>
    <td rowspan=2 align='center'>RSUM</td>
  </tr>
  <tr>
    <td>R@1</td>
    <td>R@5</td>
    <td>R@10</td>
    <td>R@1</td>
    <td>R@5</td>
    <td>R@10</td>
  </tr>
  <tr>
    <td>VSE++</td>
    <td>2018 BMVC</td>
    <td>ResNet-152</td>
    <td>GRU</td>
    <td> 52.9</td><td> 80.5</td><td> 87.2</td><td> 39.6</td><td> 70.1</td><td> 79.5</td><td> 409.8</td>
  </tr>
  <tr>
    <td>SCAN</td>
    <td>2018 ECCV</td>
    <td>BUTD</td>
    <td>Bi-GRU</td>
    <td> 67.4</td><td> 90.3</td><td> 95.8</td><td> 48.6</td><td> 77.7</td><td> 85.2</td><td> 465.0</td>
  </tr>
  <tr>
    <td>VSRN</td>
    <td>2019 ICCV</td>
    <td>BUTD</td>
    <td>GRU</td>
    <td> 71.3</td><td> 90.6</td><td> 96.0</td><td> 54.7</td><td> 81.8</td><td> 88.2</td><td> 482.6</td>
  </tr>
  <tr>
    <td>GSMN</td>
    <td>2020 CVPR</td>
    <td>BUTD</td>
    <td>Bi-GRU</td>
    <td> 76.4</td><td> 94.3</td><td> 97.3</td><td> 57.4</td><td> 82.3</td><td> 89.0</td><td> 496.8</td>
  </tr>
  <tr>
    <td>SGRAF</td>
    <td>2021 AAAI</td>
    <td>BUTD</td>
    <td>Bi-GRU</td>
    <td> 77.8</td><td> 94.1</td><td> 97.4</td><td> 58.5</td><td> 83.0</td><td> 88.8</td><td> 499.6</td>
  </tr>
  <tr>
    <td>NAAF</td>
    <td>2022 CVPR</td>
    <td>BUTD</td>
    <td>Bi-GRU</td>
    <td> 81.9</td><td> 96.1</td><td> 98.3</td><td> 61.0</td><td> 85.3</td><td> 90.6</td><td> 513.2</td>
  </tr>
</table>

### Performance on MS-COCO 1K

### Performance on MS-COCO 5K

